# Analytics System  
A fast, asynchronous website analytics backend that captures events, processes them using a queue + worker pipeline, stores them in SQLite, and exposes reporting APIs with optional dashboard visualizations.

---

## ğŸ“Œ Problem Statement (Summary)
The goal is to design a lightweight analytics system that:
- Handles a high volume of events **without slowing the client**
- Accepts events instantly and processes them asynchronously
- Stores all events in a database through a background worker
- Provides a summary analytics API (not raw events)
- Optionally visualizes analytics using a dashboard UI

---

# ğŸ— Architecture Overview

This system consists of **two backend services** and an **optional frontend dashboard**.

---

## âœ” **1. Ingestion + Worker Service** (combined backend service)
Located inside **`ingestion-service/`**

Handles:
- `POST /event` â€” receives analytics events  
- Pushes events into a **shared in-memory queue**  
- A **background worker (`worker.js`)** continuously reads from the queue  
- Events are stored into **SQLite (`events.db`)**

Flow:
```
Client â†’ POST /event â†’ queue â†’ worker â†’ SQLite (events.db)
```

---

## âœ” **2. Reporting Service**
Located inside **`reporting-service/`**

Endpoint:
- `GET /stats?site_id=XYZ&date=YYYY-MM-DD`

Returns:
- total views  
- unique users  
- top visited paths  
- date-level summary  

This satisfies the problem requirement of showing **aggregated analytics only**, not raw events.

---

## âœ” **3. (Optional) Dashboard UI**
Located inside **`dashboard/`**

A React-based visualization showing:
- Total events  
- Timeline chart  
- Raw events  
- Top paths  
- User activity patterns  

---

# ğŸ§  Architecture Decision

### â­ Why use a Queue + Worker (Asynchronous Processing)?
The problem specifically mentions:
- Client should not wait  
- Processing must be asynchronous  
- Ingestion must be fast  

If the ingestion API wrote directly to the database:
- It would be slow  
- Under high load, it could fail  

So we use:
- In-memory queue (`queue.js`)
- Worker (`worker.js`) running inside ingestion-service

This ensures:
- Ingestion is **instant**
- Processing happens in background
- System scales well under load

This satisfies the required architecture **perfectly**.

---

# ğŸ—„ Database Schema

### Table: **events**

| Column     | Type    | Description |
|------------|---------|-------------|
| id         | INTEGER | Auto-increment primary key |
| site_id    | TEXT    | Identifier for site |
| event_type | TEXT    | Event type (e.g., `page_view`) |
| path       | TEXT    | URL path |
| user_id    | TEXT    | User identifier |
| timestamp  | TEXT    | ISO timestamp |

### Schema Diagram

```
events
 â”œâ”€â”€ id (PK)
 â”œâ”€â”€ site_id
 â”œâ”€â”€ event_type
 â”œâ”€â”€ path
 â”œâ”€â”€ user_id
 â””â”€â”€ timestamp
```

---

# ğŸ“‚ Folder Structure

```
Analytics_system/
â”œâ”€â”€ ingestion-service/
â”‚   â”œâ”€â”€ index.js       # Ingestion API
â”‚   â”œâ”€â”€ worker.js      # Background worker
â”‚   â”œâ”€â”€ queue.js       # Shared in-memory queue
â”‚   â””â”€â”€ events.db      # SQLite database
â”‚
â”œâ”€â”€ reporting-service/
â”‚   â””â”€â”€ index.js       # Summary stats API
â”‚
â”œâ”€â”€ dashboard/         # Optional React visualization
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

---

# âš™ï¸ Setup Instructions

## 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/Dhanya04sh/Analytics_system
cd Analytics_system
```

---

# ğŸŸ¦ BACKEND SETUP

## 2ï¸âƒ£ Start Ingestion + Worker Service
```sh
cd ingestion-service
npm install
node index.js
```

This runs:
- Ingestion API â†’ **http://localhost:3001**
- Worker â†’ processes queue â†’ writes to SQLite

---

## 3ï¸âƒ£ Start Reporting Service
```sh
cd ../reporting-service
npm install
node index.js
```

This runs:
- Reporting API â†’ **http://localhost:3002**

---

# ğŸŸ© OPTIONAL: DASHBOARD UI (React)

## 4ï¸âƒ£ Start Dashboard
```sh
cd ../dashboard
npm install
npm run dev
```

Access dashboard at:
```
http://localhost:5173
```

---

# ğŸ§ª API Usage Examples

## âœ” Send an event

```sh
curl -X POST http://localhost:3001/event \
-H "Content-Type: application/json" \
-d "{
  \"site_id\":\"site-123\",
  \"event_type\":\"page_view\",
  \"path\":\"/home\",
  \"user_id\":\"u10\",
  \"timestamp\":\"2025-11-14T10:00:00Z\"
}"
```

Response:
```json
{"status":"queued"}
```

---

## âœ” Get analytics summary

```sh
curl "http://localhost:3002/stats?site_id=site-123"
```

or with date:

```sh
curl "http://localhost:3002/stats?site_id=site-123&date=2025-11-14"
```

Example response:
```json
{
  "site_id": "site-123",
  "date": "2025-11-14",
  "total_views": 1200,
  "unique_users": 180,
  "top_paths": [
    { "path": "/home", "views": 400 },
    { "path": "/pricing", "views": 300 },
    { "path": "/blog", "views": 200 }
  ]
}
```

---

# ğŸ§° Tech Stack

### Backend
- Node.js  
- Express  
- SQLite  

### Queue
- Shared in-memory queue (`queue.js`)

### Frontend (optional)
- React  
- Vite  
- TailwindCSS  
- Recharts  

---

# ğŸš€ Future Enhancements
- Use Redis/RabbitMQ for distributed queuing  
- Move from SQLite â†’ PostgreSQL  
- Add authentication  
- Add dashboards for multi-site analytics  
- Real-time updates using WebSockets  
- Dockerize entire system  

---

# ğŸ“„ License
MIT License

---

# ğŸ‰ End of README  
Your analytics system is fully documented with all required deliverables.
